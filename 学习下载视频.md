记录学习第1天

```python

import os.path    # OS路径
import time       # 时间模块
import requests_cache  
requests_cache.install_cache('demo_cache')    # 缓存语句，对已经下载获取的网页，不再重复获取
import requests   # 网页数据获取
from fake_useragent import UserAgent      # 假浏览器headers
from lxml import etree         # 数据解析
from multiprocessing.dummy import Pool       # 多线程进行下载
# 开始时间   
start_time = time.time()  
# 初始设定  
pool = Pool(5)  
headers = {'User-agent': UserAgent().random}  
# 设定文件保存路径  
path_91 = '91_video_text'  
if not os.path.exists(path_91):  
    os.mkdir(path_91)  
# 设定视频保存路径  
path_video_91 = '91_video'  
if not os.path.exists(path_video_91):  
    os.mkdir(path_video_91)  
  
# 获取91视频页面的数据：单个视频的链接  
def get_91web_html(url):  
    resp = requests.get(url=url, headers=headers)  
    resp.encoding = resp.apparent_encoding  
    # 发现只能得到视频的链接，视频的名字是英文  
    tree = etree.HTML(resp.text)  
    # 得到单个视频的链接，等待后面点击  
    url_91_one = tree.xpath('//*[@id="wrapper"]/div[1]/div[3]/div/div/div/div/a/@href')  
    # print(url_91_one)  
    return url_91_one  
  
# 获取单个页面的数据，得到视频的下载链接 和视频名称  进行保存  
def get_video_date(url):  
    resp = requests.get(url=url, headers=headers)  
    # resp.encoding = resp.apparent_encoding  
    tree = etree.HTML(resp.text)  
    # 获取到视频的 名称代码，进行保存。因为获取到的视频名称，都是英文。  可能是爬虫获取网页的问题，留待解决  
    video_name_false = tree.xpath('//*[@id="player_one"]/@poster')[0]  
    video_name = video_name_false.split('/')[-1].split('.')[0].strip()  
    # print(video_name)  
    # 获取视频的下载链接，通过第三方插件，发现 m3u8的下载链接为：src="https://la.killcovid2021.com/m3u8/654373/654373.m3u8"  
    # 进行链接构造  
    video_url = f'https://la.killcovid2021.com/m3u8/{video_name}/{video_name}.m3u8'  
    print(video_url)  
    return video_name,video_url  
  
  
# 下载单个视频的数据，并以txt的格式保存在文件夹内  
def down_91_video(video_name,video_url):  
    r = requests.get(url=video_url,headers=headers).text  
    with open(f'{path_91}/{video_name}.txt','w',encoding='utf-8') as f:  
        f.write(r)  
  
# 读取文件夹内的TXT数据，获取所有的视频文件名  
def get_down_video_list():  
    if len(path_91) != 0:  
        print(os.listdir(path_91))  
        files_list = os.listdir(path_91)  
        return files_list  
  
# 从保存的txt文件夹中读取文件名，并进行下载  
def down_91_video_to_mp4(file_name):  
    # 构建下载链接所需要的视频代码  
    f_name = file_name.split('.')[0]  
    # 构建打开文件路径  
    open_path = f'{path_91}/{file_name}'  
    with open(open_path, 'r') as f:  
        f2 = f.readlines()  
        for ff in f2:  
            if not ff.startswith('#'):  
                # print(ff.strip())  
                # 进行视频下载  
                uurl = f'https://cdn77.91p49.com/m3u8/{f_name}/{ff.strip()}'  
                r2 = requests.get(url=uurl, headers=headers).content  
                with open(f'{path_video_91}/{f_name}.mp4', 'ab+') as f3:  
                    f3.write(r2)  
    print(f'{file_name}已下载成功，现在进行删除')  
    os.remove(open_path)  
  
if __name__ == '__main__':  
    # 这里暂时只采集首页视频  
    url = 'http://91porn.com/v.php?next=watch'  
    # 得到所有单个的视频集合  
    urls = get_91web_html(url)  
    # 从首页链接中进入，进行视频分析下载  
    for u in urls:  
        # 获取单个视频的代码名称和链接  
        try:  
            video_name,video_url = get_video_date(u)  
            # 将m3u8文件保存到文件夹内  
            down_91_video(video_name,video_url)  
        except:  
            continue  
        # 获取文件夹内已下载的 视频代码名称  
    files_list = get_down_video_list()  
    # 进行单个视频的下载，并进行保存,这里使用多线程的方法  
    pool.map(down_91_video_to_mp4,files_list)  
    print('运行结束')  
  
# 结束时间  
end_time =time.time()  
  
print(f'共消耗{end_time-start_time}秒')
```